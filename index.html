<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Nerfies: Deformable Neural Radiance Fields</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale- and Geometry-Consistent Video Depth Estimation
</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yuejiangdong.github.io">Yue-Jiang Dong</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://thuzhaowang.github.io">Wang Zhao</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://bluestyle97.github.io">Jiale Xu</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://www.linkedin.com/in/YingShanProfile/">Ying Shan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=AWtV-EQAAAAJ&hl=en">Song-Hai Zhang</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tsinghua University,</span>
            <span class="author-block"><sup>2</sup>ARC Lab, Tencent PCG</span>
          </div>

          <div class="is-size-4 publication-conference">
            <b>ICCV 2025</b>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2507.01603"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2507.01603"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
          <br>
          <br>
           <!-- Teaser -->
            <div class="columns is-1 is-multiline is-mobile">
              <img src="./static/images/teaser.jpg" alt="Teaser" style="width:120%">
               
            </div>
          <div>
            DepthSync is a framework that introduces cross-window depth scale synchronization and intra-window geometry alignment to achieve long video depth predictions with enhanced scale and geometry consistency via diffusion guidance.
          </div>

        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Diffusion-based video depth estimation methods have achieved remarkable success with strong generalization ability. However, predicting depth for long videos remains  challenging. Existing methods typically split videos into overlapping sliding windows, leading to accumulated scale discrepancies across different windows, particularly as the number of windows increases. Additionally, these methods rely solely on 2D diffusion priors, overlooking the inherent 3D geometric structure of video depths, which results in geometrically inconsistent predictions.
          </p>
          <p>
            In this paper, we propose DepthSync, a novel, training-free framework using diffusion guidance to achieve scale- and geometry-consistent depth predictions for long videos. Specifically, we introduce <b>scale guidance</b> to synchronize the depth scale <b>across windows</b> and <b>geometry guidance</b> to enforce geometric alignment <b>within windows</b> based on the inherent 3D constraints in video depths. These two terms work synergistically, steering the denoising process toward consistent depth predictions. Experiments on various datasets validate the effectiveness of our method in producing depth estimates with improved scale and geometry consistency, particularly for long videos.
          </p><br>
        </div>
      </div>
      
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
    <div class="columns is-1 is-multiline is-mobile">
        <img src="./static/images/pipeline.pdf" alt="Teaser" style="width:120%">
      </div>
      <div>
        <b>Pipeline. </b> Our DepthSync framework predicts depth for a monocular video by applying guidance to a pre-trained diffusion-based depth estimation model, ensuring scale- and geometry-consistent depth predictions. Following common practice, the input video is split into overlapping windows and processed sequentially. During denoising, we derive depths from noise prediction, applying geometry guidance to align frames within each window using geometric constraints and scale guidance to synchronize depth scales across windows.
      </div>
  </div>
</section>





<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{dong2025depthsync,
  title={DepthSync: Diffusion Guidance-Based Depth Synchronization for Scale-and Geometry-Consistent Video Depth Estimation},
  author={Dong, Yue-Jiang and Zhao, Wang and Xu, Jiale and Shan, Ying and Zhang, Song-Hai},
  journal   = {ICCV},
  year      = {2025},
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered"> -->
      <!-- <a class="icon-link" href="https://arxiv.org/abs/">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a
        class="icon-link"
        href="https://github.com/TencentARC/DI-PCG"
        class="external-link"
        disabled>
        <i class="fab fa-github"></i>
      </a> -->
    <!-- </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p style="text-align: center">
            The website template is borrowed from
            <a href="https://nerfies.github.io/" target="_blank">Nerfies</a
            >.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
